# RAG POC Architecture Diagram

## System Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                    RAG POC Architecture                         │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Input Layer   │    │  Processing     │    │   Storage       │
│                 │    │    Layer        │    │    Layer        │
├─────────────────┤    ├─────────────────┤    ├─────────────────┤
│ • Text          │───▶│ • Sentence      │──▶│ • ChromaDB      │
│   Documents     │    │   Transformers  │    │   Vector Store  │
│ • Queries       │    │ • Embeddings    │    │ • Local Files   │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │                        │
                                ▼                        ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Search        │    │   Retrieval     │    │   Output        │
│   Layer         │    │   Layer         │    │   Layer         │
├─────────────────┤    ├─────────────────┤    ├─────────────────┤
|                 ◀── |                 |    |                 |
└─────────────────┘    └─────────────────┘    │                 │
                                              └─────────────────┘
```

## Detailed Component Flow

### 1. Document Ingestion
```
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ Raw Text    │───▶│ Sentence    │───▶│ Vector      │
│ Documents   │    │ Transformer │     │ Embeddings  │
│             │    │ (Model)│    │     │             |
└─────────────┘    └─────────────┘     └─────────────┘
```

A **vector embedding** is a numerical representation of text that captures its meaning, allowing similar texts to be compared and retrieved efficiently using mathematical operations.  This embedding is generated by the sentence transformer's model on the raw document text.



### 2. Storage & Indexing
```
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ Vector      │───▶│ ChromaDB    │───▶│ Persistent  │
│ Embeddings  │    │ Collection  │     │ Storage     │
│             │    │             │     │ (./chroma_db)│
└─────────────┘    └─────────────┘     └─────────────┘
```

### 3. Query Processing
```
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ User Query  │───▶│ Query       │───▶│ Similarity  │
│             │    │ Embedding   │     │ Search      │
└─────────────┘    └─────────────┘     └─────────────┘
                                           │
                                           ▼
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ Search      │◀── │ Top-K       │◀───│ Cosine      │
│ Output      │    │  Results    │     │ Distance    │
│             │    │             │     │ Calculation │
└─────────────┘    └─────────────┘     └─────────────┘
```

The **query embedding** is a vector representation of the user's query, generated on-the-fly by the sentence transformer model. ChromaDB compares this to stored document embeddings using **cosine similarity** to find and return the most relevant document chunks. The query embedding is not saved—it's used only during the search.

ChromaDB retrieves the **top-k** most similar document chunks, where *k* is a configurable number (for example, 3). These top-k results represent the document sections that are most relevant to the user's query, ranked by their similarity score.


## Technology Stack

```
┌─────────────────────────────────────────────────────────────┐
│                    Technology Stack                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │ ChromaDB    │  │ Sentence    │  │ Python      │          │
│  │ Vector DB   │  │ Transformers│  │ 3.8+        │          │
│  │ (Local)     │  │ (all-MiniLM)│  │             │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
│                                                             │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## Key Features

- ✅ **Local Processing**: All components run on your machine
- ✅ **Persistent Storage**: Documents saved to local filesystem
required
- ✅ **Scalable**: Can handle small to medium datasets efficiently
- ✅ **Free Dependencies**: Uses open-source libraries with no usage costs
- ✅ **Scalable**: Can handle small to medium document collections
- ✅ **Extensible**: Easy to add new document types and search 
- ✅ **Vector Database Advantage**: Uses a vector database (ChromaDB) because traditional databases like SQL are not optimized for storing and querying large vector data. Vector databases are designed for efficient similarity search on high-dimensional embeddings, enabling fast and accurate retrieval of relevant document chunks.


## Performance Characteristics

```
┌─────────────────────────────────────────────────────────────┐
│                    Performance Profile                      │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Model: all-MiniLM-L6-v2                                    │
│  • Embedding Speed:      n/a                                │
│  • Search Speed:         n/a                                │
│  • Memory Usage:         507.7 MB                           │
│  • Storage:              32.5 MB                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```
