# RAG POC Architecture Diagram

## System Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                    RAG POC Architecture                         │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Input Layer   │    │  Processing     │    │   Storage       │
│                 │    │    Layer        │    │    Layer        │
├─────────────────┤    ├─────────────────┤    ├─────────────────┤
│ • Text          │───▶│ • Sentence      │──▶│ • ChromaDB      │
│   Documents     │    │   Transformers  │    │   Vector Store  │
│ • Queries       │    │ • Embeddings    │    │ • Local Files   │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │                        │
                                ▼                        ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Search        │    │   Retrieval     │    │   Output        │
│   Layer         │    │   Layer         │    │   Layer         │
├─────────────────┤    ├─────────────────┤    ├─────────────────┤
|                 ◀── |                 |    |                 |
└─────────────────┘    └─────────────────┘    │                 │
                                              └─────────────────┘
```

## Detailed Component Flow

### 1. Document Ingestion
```
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ Raw Text    │───▶│ Sentence    │───▶│ Vector      │
│ Documents   │    │ Transformer │     │ Embeddings  │
│             │    │ (Model)│    │     │             |
└─────────────┘    └─────────────┘     └─────────────┘
```

A **vector embedding** is a numerical representation of text that captures its meaning, allowing similar texts to be compared and retrieved efficiently using mathematical operations.  This embedding is generated by the sentence transformer's model on the raw document text.



### 2. Storage & Indexing
```
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ Vector      │───▶│ ChromaDB    │───▶│ Persistent  │
│ Embeddings  │    │ Collection  │     │ Storage     │
│             │    │             │     │ (./chroma_db)│
└─────────────┘    └─────────────┘     └─────────────┘
```

### 3. Query Processing
```
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ User Query  │───▶│ Query       │───▶│ Similarity  │
│             │    │ Embedding   │     │ Search      │
└─────────────┘    └─────────────┘     └─────────────┘
                                           │
                                           ▼
┌─────────────┐    ┌─────────────┐     ┌─────────────┐
│ Search      │◀── │ Top-K       │◀───│ Cosine      │
│ Output      │    │  Results    │     │ Distance    │
│             │    │             │     │ Calculation │
└─────────────┘    └─────────────┘     └─────────────┘
```

The **query embedding** is a vector representation of the user's query, generated on-the-fly by the sentence transformer model. ChromaDB compares this to stored document embeddings using **cosine similarity** to find and return the most relevant document chunks. The query embedding is not saved—it's used only during the search.

ChromaDB retrieves the **top-k** most similar document chunks, where *k* is a configurable number (for example, 3). These top-k results represent the document sections that are most relevant to the user's query, ranked by their similarity score.


## Technology Stack

```
┌─────────────────────────────────────────────────────────────┐
│                    Technology Stack                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │ ChromaDB    │  │ Sentence    │  │ Python      │          │
│  │ Vector DB   │  │ Transformers│  │ 3.8+        │          │
│  │ (Local)     │  │ (all-MiniLM)│  │             │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
│                                                             │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## Key Features

- ✅ **Local Processing**: All components run on your machine
- ✅ **Persistent Storage**: Documents saved to local filesystem
required
- ✅ **Scalable**: Can handle small to medium datasets efficiently
- ✅ **Free Dependencies**: Uses open-source libraries with no usage costs
- ✅ **Scalable**: Can handle small to medium document collections
- ✅ **Extensible**: Easy to add new document types and search 
- ✅ **Vector Database Advantage**: Uses a vector database (ChromaDB) because traditional databases like SQL are not optimized for storing and querying large vector data. Vector databases are designed for efficient similarity search on high-dimensional embeddings, enabling fast and accurate retrieval of relevant document chunks.


## Performance Characteristics

┌─────────────────────────────────────────────────────────────┐
│ Performance Profile │
├─────────────────────────────────────────────────────────────┤
│ │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Model Comparison │ │
│ ├─────────────────────────────────────────────────────────┤ │
│ │ │ │
│ │ ┌─────────────────────────────────────────────────────┐ │ │
│ │ │ all-MiniLM-L6-v2 (Current) │ │ │
│ │ ├─────────────────────────────────────────────────────┤ │ │
│ │ │ • Memory Usage: 507.7 MB │ │ │
│ │ │ • Storage: 32.5 MB │ │ │
│ │ └─────────────────────────────────────────────────────┘ │ │
│ │ │ │
│ │ ┌─────────────────────────────────────────────────────┐ │ │
│ │ │ paraphrase-multilingual-mpnet-base-v2               │ │ │
│ │ ├─────────────────────────────────────────────────────┤ │ │
│ │ │ • Memory Usage: 740.8 MB │ │ │
│ │ │ • Storage: 112.7 MB │ │ │
│ │ └─────────────────────────────────────────────────────┘ │ │
│ │ │ │
│ └─────────────────────────────────────────────────────────┘ │
│ │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Configuration │ │
│ ├─────────────────────────────────────────────────────────┤ │
│ │ │ │
│ │ • n_results: 10 (configured by default in ChromaDB) │ │
│ │ • chunk_size: 200 words (configured by default in ChromaDB) │ 
│ │ • overlap: 50 words (configured by default in ChromaDB) │ │
│ │ • Distance Metric: Cosine Similarity (configured by default in ChromaDB) │ │
│ │ │ │
│ └─────────────────────────────────────────────────────────┘ │
│ │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Recent Updates │ │
│ ├─────────────────────────────────────────────────────────┤ │
│ │ │ │
│ │ ✅ Updated model that provides improved semantic understanding ||
│ │ ✅ Added best answer selection │ │
│ │ ✅ Added transformer with answer extraction with context awareness  │ │
│ │ ✅ Increased n_results to 10  3 for better context quality(tradeoff : increases memory)│ │
│ │ │ │
│ └─────────────────────────────────────────────────────────┘ │
│ │
│ ┌─────────────────────────────────────────────────────────┐ │
│ │ Current Sample Queries │ │
│ ├─────────────────────────────────────────────────────────┤ │
│ │ │ │
│ │ Q: "how often must access reviews be performed?" │ │
│ │ A: "quarterly" │ │
│ │ │ │
│ │ Q: "how many levels is Company data classified?" │ │
│ │ A: "three" │ │
│ │ │ │
│ │ Q: "what levels is Company data classified?" │ │
│ │ A: "Public, Internal, and Confidential" │ │
│ │ │ │
│ └─────────────────────────────────────────────────────────┘ │
│ │
└─────────────────────────────────────────────────────────────┘

